---
# Get YAML keywords from myYAML_ref.Rmd
title: "Similar Sentences: Locality Sensitive Hashing application"
author: "bdanalytics"
#output: html_document
---
#### Date: `r format(Sys.time(), "(%a) %b %d, %Y")`

Data:   
Source: 
Time period: 

### Synopsis:

Potential next steps include:

```{r set_global_options}
rm(list=ls())
set.seed(12345)
source("~/Dropbox/datascience/R/mydsutils.R")
source("~/Dropbox/datascience/R/myplot.R")
# Gather all package requirements here
suppressPackageStartupMessages(require(knitr))
suppressPackageStartupMessages(require(plyr))
```

```{r set_global_options_wd, echo=FALSE}
setwd("~/Documents/Work/Courses/Coursera/mining-massive-datasets/Project/similar-sentences")
```

### Step 01: import data
```{r import_data, cache=TRUE}
sentences_df <- myimport_data(
    "https://d396qusza40orc.cloudfront.net/mmds/datasets/sentences.txt.zip", 
    "sentences.txt", nrows=1000, stringsAsFactors=FALSE)
names(sentences_df) <- "raw"
```

#### Step 02.1: inspect data
```{r inspect_steps_1, cache=TRUE}
dep_prev()
# sentences_df <- mutate(sentences_df, tokens_lst=strsplit(raw, " "), 
#                        tokens=unlist(tokens_lst))
# sentences_df <- mutate(sentences_df, id=strsplit(raw, " ")[[1]][1])
# sentences_df <- mutate(sentences_df, words_n=length(words_lst))

# Create new features that help analyses
sentences_df$id <- sapply(sentences_df$raw, 
                          function(raw) as.integer(strsplit(raw, " ")[[1]][1]))
sentences_df$words_lst <- sapply(sentences_df$raw, 
                                 function(raw) { 
                                     lst <- strsplit(raw, " ")[[1]]
                                     list(unlist(lst)[seq.int(2, length(lst))])
                                               })
sentences_df$words_n <- sapply(sentences_df$words_lst, length)
sentences_df$words_first <- sapply(sentences_df$words_lst, 
                                   function (words_lst) unlist(words_lst)[1])
sentences_df$words_last <- sapply(sentences_df$words_lst, 
                                  function (words_lst) unlist(words_lst)[length(words_lst)])
print(str(subset(sentences_df, select=-c(words_lst))))

# List info gathered for various columns
# raw:
# id:           int:    record id
# words_lst:    list:   words in this sentence
# words_n:      int:    number of words in this sentence
# words_first   string: first word in sentence
# words_lst     string: last word in sentence

#print(summary(sentences_df))
# generates a very long output
print(summary(subset(sentences_df, select=-c(words_lst))))

#pairs(subset(entity_df, select=-c(col_symbol)))
sentences_df <- subset(sentences_df, select=-c(raw))
```

Sort the sentences by number of words
```{r hash_words_n, cache=TRUE}
dep_prev()
sentences_df <- sentences_df[order(sentences_df$words_n), ]
```

Find potential pairs with edit distance at most 1 to be compared. 
This implies that for any query sentence, we need only compare that with sentences that have +/- 1 words length 
```{r find_compare_pairs, cache=TRUE}
dep_prev()
comparison_pairs_df <- data.frame()
#row_num <- 3
for (row_num in seq(1:nrow(sentences_df))) {    
    row_words_n <- sentences_df[row_num, "words_n"]
    row_id <- sentences_df[row_num, "id"]
    row_words_first <- sentences_df[row_num, "words_first"]
    row_words_last <- sentences_df[row_num, "words_last"]
    sentences_compare_df <- sentences_df[((sentences_df$words_n >= (row_words_n - 1)) & 
                                          (sentences_df$words_n <= (row_words_n + 1)) & 
                                          (sentences_df$id != row_id) &
                                          (sentences_df$id < row_id) # to avoid dups 
                                         ) &
                                         ((sentences_df$words_first == row_words_first) | 
                                          (sentences_df$words_last == row_words_last)
                                         )
                                         , c("id", "words_n")]
    comparison_pairs_df <- rbind(comparison_pairs_df, 
                                 data.frame(query_id=rep(row_id, 
                                                         nrow(sentences_compare_df)),
                                            query_words_n=rep(row_words_n, 
                                                              nrow(sentences_compare_df)),
                                            compare_id=sentences_compare_df$id,
                                            compare_words_n=sentences_compare_df$words_n))
    #print(sprintf("row_num:%d", row_num))
    #print(comparison_pairs_df)
}
print(sprintf("Pairs to be checked: %s", 
              format(nrow(comparison_pairs_df), big.mark=',')))
print(sprintf("Comparison density: %0.4f", 
              nrow(comparison_pairs_df) / (nrow(sentences_df) ^ 2)))
myprint_df(comparison_pairs_df)
```

```{r compare_pairs, cache=TRUE}
dep_prev()
sentence_edit_distance <- function(words_lst1, words_lst2) {
    words1 <- sort(unlist(words_lst1))
    words2 <- sort(unlist(words_lst2))
    return(length(union(words1, words2)) - length(intersect(words1, words2)))
}
#sentence_edit_distance(compare_pairs_row_words_lst1, compare_pairs_row_words_lst2)

for (row in seq(1, nrow(comparison_pairs_df))) {
    row_id1 <- comparison_pairs_df[row, "query_id"]
    row_id2 <- comparison_pairs_df[row, "compare_id"]
    row_words_lst1 <- sentences_df[sentences_df$id == row_id1, "words_lst"]
    row_words_lst2 <- sentences_df[sentences_df$id == row_id2, "words_lst"]
    comparison_pairs_df[row, "edit_distance"] <- 
        sentence_edit_distance(row_words_lst1, row_words_lst2)
}

#comparison_pairs_df <- mutate(comparison_pairs_df, 
#                              edit_distance=sentence_edit_distance(
#                        sentences_df[sentences_df$id == query_id, "words_lst"],
#                        sentences_df[sentences_df$id == compare_id, "words_lst"]
#                                                                   ))

min_edit_distance <- min(comparison_pairs_df$edit_distance)
print(sprintf("min edit distance: %d", min_edit_distance))
min_edit_distance_row <- 
    comparison_pairs_df[which(comparison_pairs_df$edit_distance == 
                              min_edit_distance)[1], ]
print(min_edit_distance_row)
print(sentences_df[sentences_df$id == min_edit_distance_row$query_id, "words_lst"])
print(sentences_df[sentences_df$id == min_edit_distance_row$compare_id, "words_lst"])

zero_edit_distance_row <- 
    comparison_pairs_df[which(comparison_pairs_df$edit_distance == 
                              0)[1], ]
print(zero_edit_distance_row)
print(sentences_df[sentences_df$id == zero_edit_distance_row$query_id, "words_lst"])
print(sentences_df[sentences_df$id == zero_edit_distance_row$compare_id, "words_lst"])

one_edit_distance_row <- 
    comparison_pairs_df[which(comparison_pairs_df$edit_distance == 
                              1)[1], ]
print(one_edit_distance_row)
#print(sentences_df[sentences_df$id == one_edit_distance_row$query_id, "words_lst"])
#print(sentences_df[sentences_df$id == one_edit_distance_row$compare_id, "words_lst"])

```

```{r print_sessionInfo, echo=FALSE}
sessionInfo()
```