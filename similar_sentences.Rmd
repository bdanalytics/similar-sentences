---
title: 'Similar Sentences: Locality Sensitive Hashing application'
author: "bdanalytics"
output:
  html_document:
    highlight: tango
---
#### Date: `r format(Sys.time(), "(%a) %b %d, %Y")`

Data:   
Source: 
Time period: 

### Synopsis:

Potential next steps include:

```{r set_global_options}
rm(list=ls())
set.seed(12345)
source("~/Dropbox/datascience/R/mydsutils.R")
source("~/Dropbox/datascience/R/myplot.R")
# Gather all package requirements here
suppressPackageStartupMessages(require(knitr))
suppressPackageStartupMessages(require(plyr))
suppressPackageStartupMessages(require(reshape))
```

```{r set_global_options_wd, echo=FALSE}
setwd("~/Documents/Work/Courses/Coursera/mining-massive-datasets/Project/similar-sentences")
```

### Step 01: import data
```{r import_data, cache=TRUE}
sentences_df <- myimport_data(
    "https://d396qusza40orc.cloudfront.net/mmds/datasets/sentences.txt.zip", 
    "sentences.txt", nrows=2000, stringsAsFactors=FALSE)
names(sentences_df) <- "raw"
```

#### Step 02.1: inspect data
```{r inspect_steps_1, cache=TRUE, autodep=TRUE}
#```{r inspect_steps_1}
# dep_prev()
# sentences_df <- mutate(sentences_df, tokens_lst=strsplit(raw, " "), 
#                        tokens=unlist(tokens_lst))
# sentences_df <- mutate(sentences_df, id=strsplit(raw, " ")[[1]][1])
# sentences_df <- mutate(sentences_df, words_n=length(words_lst))

# Create new features that help analyses
sentences_df$id <- sapply(sentences_df$raw, 
                          function(raw) as.integer(strsplit(raw, " ")[[1]][1]))
sentences_df$words_lst <- sapply(sentences_df$raw, 
                                 function(raw) { 
                                     lst <- strsplit(raw, " ")[[1]]
                                     list(unlist(lst)[seq.int(2, length(lst))])
                                               })
sentences_df$words_n <- sapply(sentences_df$words_lst, length)
sentences_df$words_first <- sapply(sentences_df$words_lst, 
                                   function (words_lst) unlist(words_lst)[1])
sentences_df$words_last <- sapply(sentences_df$words_lst, 
                                  function (words_lst) unlist(words_lst)[length(words_lst)])
print(str(subset(sentences_df, select=-c(words_lst))))

# List info gathered for various columns
# raw:
# id:           int:    record id
# words_lst:    list:   words in this sentence
# words_n:      int:    number of words in this sentence
# words_first   string: first word in sentence
# words_lst     string: last word in sentence

#print(summary(sentences_df))
# generates a very long output
print(summary(subset(sentences_df, select=-c(words_lst))))

#pairs(subset(entity_df, select=-c(col_symbol)))
sentences_df <- subset(sentences_df, select=-c(raw))
```

Sort the sentences by number of words
```{r hash_words_n, cache=TRUE, autodep=TRUE}
#```{r hash_words_n}
sentences_df <- sentences_df[order(sentences_df$words_n), ]
print(head(sentences_df))
```

Find potential pairs with edit distance at most 1 to be compared. 
This implies that for any query sentence, we need only compare that with sentences that have +/- 1 words length 
```{r find_compare_pairs, cache=TRUE, autodep=TRUE}
#```{r find_compare_pairs}
print(nrow(sentences_df))
comparison_pairs_df <- data.frame()
#row_pos <- which(sentences_df$id == 352)
loop_step_id_set <- c(  "1_Identified_Query"
                      , "2_Filtered_Length"
                      , "3_Filtered_Dups"
                      , "4_Filtered_FirstLast"
                      , "5_Created_DFrame"
                      , "6_Appended_DFrame"
                     )
loop_steps_time_df <- data.frame(loop_step_id=loop_step_id_set)
loop_steps_time_df[, names(summary(proc.time()))] <- 
    rep(0, length(names(summary(proc.time()))) * nrow(loop_steps_time_df)) 

for (loop_step_id in loop_steps_time_df$loop_step_id) {
#for (loop_step_id in loop_steps_time_df$loop_step_id[seq(2, 3)]) {   
    ptm <- proc.time()
    ptm_diff <- proc.time() - ptm

    for (row_pos in seq(1:nrow(sentences_df))) {    
        
        if (loop_step_id >= loop_step_id_set[1]) {
            row_words_n <- sentences_df[row_pos, "words_n"]
            row_id <- sentences_df[row_pos, "id"]
            row_words_first <- sentences_df[row_pos, "words_first"]
            row_words_last <- sentences_df[row_pos, "words_last"]
        }
        
        if (loop_step_id >= loop_step_id_set[2]) {
            sentences_chk_df <- subset(sentences_df, 
                                       (sentences_df$words_n >= (row_words_n - 1)) & 
                                       (sentences_df$words_n <= (row_words_n + 1))
                                      )
        }
        if (loop_step_id >= loop_step_id_set[3]) {        
            sentences_chk_df <- subset(sentences_chk_df,
                                       (sentences_chk_df$id != row_id) &
                                       (sentences_chk_df$id < row_id) # to avoid dups       
                                      )
        }
        if (loop_step_id >= loop_step_id_set[4]) {        
            sentences_compare_df <- sentences_chk_df[ 
                                ((sentences_chk_df$words_first == row_words_first) | 
                                 (sentences_chk_df$words_last == row_words_last)
                                )
                                                     , c("id", "words_n")]
        }
        
        if (loop_step_id >= loop_step_id_set[5]) {
            query_pairs_df <- 
                      data.frame(query_id=rep(row_id, nrow(sentences_compare_df)),
                                 query_words_n=rep(row_words_n, 
                                                   nrow(sentences_compare_df)),
                                 compare_id=sentences_compare_df$id,
                                 compare_words_n=sentences_compare_df$words_n)
        }
            
        if (loop_step_id >= loop_step_id_set[6]) {            
            comparison_pairs_df <- rbind(comparison_pairs_df, query_pairs_df)
            #print(sprintf("row_pos:%d", row_pos))
            #print(comparison_pairs_df)
        }
    }
    ptm_diff <- proc.time() - ptm
    loop_steps_time_df[loop_steps_time_df$loop_step_id == loop_step_id, 
                       names(summary(ptm_diff))] <- summary(ptm_diff)
}
print(loop_steps_time_df)
loop_steps_plot_df <- melt(loop_steps_time_df, id="loop_step_id", 
                           measure=c("user", "system", "elapsed"))
p <- ggplot(data=loop_steps_plot_df, mapping=aes(x=loop_step_id, y=value)) + 
        geom_line(aes(group=variable, color=variable)) 
#p <- p + scale_x_discrete(limits=rev(levels(loop_steps_plot_df$loop_step_id)))
print(p)

loop_steps_time_df$user_diff <- sapply(seq(1, nrow(loop_steps_time_df)), 
                                       function(step) ifelse(step <= 1, 
                                                             NA,
    loop_steps_time_df[step, "user"] - loop_steps_time_df[step - 1, "user"]))
print(loop_steps_time_df)

print(sprintf("Pairs to be checked: %s", 
              format(nrow(comparison_pairs_df), big.mark=',')))
print(sprintf("Comparison density: %0.4f", 
              nrow(comparison_pairs_df) / (nrow(sentences_df) ^ 2)))
myprint_df(comparison_pairs_df)
```

#```{r compare_pairs, cache=TRUE, autodep=TRUE}
```{r compare_pairs}
sentence_edit_distance <- function(words_lst1, words_lst2) {
    words1 <- sort(unlist(words_lst1))
    words2 <- sort(unlist(words_lst2))
    return(length(union(words1, words2)) - length(intersect(words1, words2)))
}
#sentence_edit_distance(compare_pairs_row_words_lst1, compare_pairs_row_words_lst2)

for (row in seq(1, nrow(comparison_pairs_df))) {
    row_id1 <- comparison_pairs_df[row, "query_id"]
    row_id2 <- comparison_pairs_df[row, "compare_id"]
    row_words_lst1 <- sentences_df[sentences_df$id == row_id1, "words_lst"]
    row_words_lst2 <- sentences_df[sentences_df$id == row_id2, "words_lst"]
    comparison_pairs_df[row, "edit_distance"] <- 
        sentence_edit_distance(row_words_lst1, row_words_lst2)
}

#comparison_pairs_df <- mutate(comparison_pairs_df, 
#                              edit_distance=sentence_edit_distance(
#                        sentences_df[sentences_df$id == query_id, "words_lst"],
#                        sentences_df[sentences_df$id == compare_id, "words_lst"]
#                                                                   ))

min_edit_distance <- min(comparison_pairs_df$edit_distance)
print(sprintf("min edit distance: %d", min_edit_distance))
min_edit_distance_row <- 
    comparison_pairs_df[which(comparison_pairs_df$edit_distance == 
                              min_edit_distance)[1], ]
print(min_edit_distance_row)
print(sentences_df[sentences_df$id == min_edit_distance_row$query_id, "words_lst"])
print(sentences_df[sentences_df$id == min_edit_distance_row$compare_id, "words_lst"])

zero_edit_distance_row <- 
    comparison_pairs_df[which(comparison_pairs_df$edit_distance == 
                              0)[1], ]
print(zero_edit_distance_row)
print(sentences_df[sentences_df$id == zero_edit_distance_row$query_id, "words_lst"])
print(sentences_df[sentences_df$id == zero_edit_distance_row$compare_id, "words_lst"])

one_edit_distance_row <- 
    comparison_pairs_df[which(comparison_pairs_df$edit_distance == 
                              1)[1], ]
print(one_edit_distance_row)
print(sentences_df[sentences_df$id == one_edit_distance_row$query_id, "words_lst"])
print(sentences_df[sentences_df$id == one_edit_distance_row$compare_id, "words_lst"])

```

```{r print_sessionInfo, echo=FALSE}
sessionInfo()
```